{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bf32fcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import xml.etree.ElementTree as ET\n",
    "\n",
    "class InPortValidator():\n",
    "    def __init__(self, dmp_xml_file_path: str = None,\n",
    "                 dmp_xml_element_tree: ET = None):\n",
    "        self.dmp_xml_file_path = dmp_xml_file_path\n",
    "        self.dmp_xml_element_tree = dmp_xml_element_tree\n",
    "        self._handle_xml_file()\n",
    "        self.inport_sample_url = \"https://www.fisheries.noaa.gov/inport/help/xml-loader/inport-xml-sample-dmp.xml\"\n",
    "        self.sample_root = self.load_xml_from_url(self.inport_sample_url)\n",
    "        self._set_valid_values_from_sample_xml()\n",
    "    \n",
    "    def _handle_xml_file(self):\n",
    "        # Handles the XML file provided in the init by loading self.root\n",
    "        # correctly\n",
    "        if (self.dmp_xml_file_path is None) and (self.dmp_xml_element_tree is None):\n",
    "            raise ValueError(\"Either dmp_xml_file_path or dmp_xml_element_tree must be provided\")\n",
    "        assert (self.dmp_xml_file_path is not None) ^ (self.dmp_xml_element_tree is not None), \\\n",
    "            \"Either dmp_xml_file_path or dmp_xml_element_tree must be provided, but not both.\"\n",
    "\n",
    "        if self.dmp_xml_file_path:\n",
    "            # Load XML from file path\n",
    "            self.root = ET.parse(self.dmp_xml_file_path).getroot()\n",
    "        else:\n",
    "            # Use the provided ElementTree root element\n",
    "            self.root = self.dmp_xml_element_tree.getroot()\n",
    "\n",
    "    def load_xml_from_url(self, url):\n",
    "        \"\"\"\n",
    "        Fetches XML content from a URL and parses it into an ElementTree root\n",
    "        element.\n",
    "        \"\"\"\n",
    "        try:\n",
    "            # Fetch the content from the URL\n",
    "            response = requests.get(url)\n",
    "            # Raise an exception if the request was unsuccessful\n",
    "            response.raise_for_status() \n",
    "\n",
    "            # The XML data is in response.content (bytes) or response.text\n",
    "            # (string)\n",
    "            # Use ET.fromstring to parse the content directly\n",
    "            root = ET.fromstring(response.content)\n",
    "            return root\n",
    "\n",
    "        except requests.exceptions.RequestException as e:\n",
    "            print(f\"Error fetching URL: {e}\")\n",
    "            return None\n",
    "        except ET.ParseError as e:\n",
    "            print(f\"Error parsing XML: {e}\")\n",
    "            return None\n",
    "    \n",
    "    def _set_valid_values_from_sample_xml(self):\n",
    "        self._set_valid_dmp_types()\n",
    "    \n",
    "    def _set_valid_dmp_types(self):\n",
    "        # Extracts and loads a list of valid DMP types from the sample XML\n",
    "        # content\n",
    "        dmp_types = self.sample_root.find(\"./general-information/dmp-type\")\n",
    "        dmp_types = dmp_types.text\n",
    "        dmp_types = dmp_types[dmp_types.find(\":\") + 1:].split(\",\")\n",
    "        dmp_types = [dmp_type.strip(\" .\") for dmp_type in dmp_types]\n",
    "        self.valid_dmp_types = dmp_types\n",
    "\n",
    "    def _validate_dmp_type(self, dmp_type: str) -> bool:\n",
    "        return dmp_type in self.valid_dmp_types\n",
    "    \n",
    "    def validate_xml(self, xml_file_path: str, xml: ET):\n",
    "        # Validate the XML content against the sample XML\n",
    "        self._validate_dmp_type()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "786b298a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Root tag: inport-metadata\n",
      "item-identification {}\n",
      "general-information {}\n",
      "program-information {}\n",
      "coverage {}\n",
      "data-acquisition {}\n",
      "data-collection {}\n",
      "contact-information {}\n",
      "resources {}\n",
      "data-protection {}\n",
      "data-lineage {}\n",
      "data-documentation {}\n",
      "data-access {}\n",
      "long-term-preservation {}\n",
      "comments {}\n",
      "related-items {'mode': 'replace'}\n",
      "catalog-details {}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "inport_sample_url = \"https://www.fisheries.noaa.gov/inport/help/xml-loader/inport-xml-sample-dmp.xml\"\n",
    "\n",
    "validator = InPortValidator()\n",
    "# Print the tag of the root element\n",
    "print(f'Root tag: {validator.sample_root.tag}')\n",
    "# Print the tag and attributes of each child element\n",
    "for child in validator.sample_root:\n",
    "    print(child.tag, child.attrib)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "0a4df381",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Initial DMP', 'Updated DMP', 'Final DMP', 'Funding Proposal DMP (Grants/CAs)', 'Updated DMP (Grants/CAs)', 'Final DMP (Grants/CAs)', 'Program-level DMP', 'No Data DMP']\n"
     ]
    }
   ],
   "source": [
    "print(validator.valid_dmp_types)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6745dd56",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max page: 3\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Org Group</th>\n",
       "      <th>Program</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NESDIS</td>\n",
       "      <td>National Environmental Satellite, Data, and In...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NESDIS</td>\n",
       "      <td>NESDIS &gt; Chief of Staff (COS)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NESDIS</td>\n",
       "      <td>NESDIS &gt; Cooperative Institute for Climate and...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NESDIS</td>\n",
       "      <td>NESDIS &gt; Cooperative Institute for Meteorologi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NESDIS</td>\n",
       "      <td>NESDIS &gt; Cooperative Institute for Research in...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199</th>\n",
       "      <td>OMAO</td>\n",
       "      <td>OMAO &gt; Marine Operations (MO)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>200</th>\n",
       "      <td>OMAO</td>\n",
       "      <td>OMAO &gt; NOAA Commissioned Corps (NOAA Corps)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201</th>\n",
       "      <td>OMAO</td>\n",
       "      <td>OMAO &gt; NOAA Diving Program (NDP)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>202</th>\n",
       "      <td>OMAO</td>\n",
       "      <td>OMAO &gt; Small Boat Program (SBP)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>203</th>\n",
       "      <td>OMAO</td>\n",
       "      <td>OMAO &gt; Uncrewed Systems Operations (UXS)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>204 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    Org Group                                            Program\n",
       "0      NESDIS  National Environmental Satellite, Data, and In...\n",
       "1      NESDIS                      NESDIS > Chief of Staff (COS)\n",
       "2      NESDIS  NESDIS > Cooperative Institute for Climate and...\n",
       "3      NESDIS  NESDIS > Cooperative Institute for Meteorologi...\n",
       "4      NESDIS  NESDIS > Cooperative Institute for Research in...\n",
       "..        ...                                                ...\n",
       "199      OMAO                      OMAO > Marine Operations (MO)\n",
       "200      OMAO        OMAO > NOAA Commissioned Corps (NOAA Corps)\n",
       "201      OMAO                   OMAO > NOAA Diving Program (NDP)\n",
       "202      OMAO                    OMAO > Small Boat Program (SBP)\n",
       "203      OMAO           OMAO > Uncrewed Systems Operations (UXS)\n",
       "\n",
       "[204 rows x 2 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "def get_max_page_number_from_inport(url: str = \"\") -> int:\n",
    "    url = \"https://www.fisheries.noaa.gov/inport/help/components/programs?page=0\"\n",
    "    r = requests.get(url)\n",
    "    soup = BeautifulSoup(r.text, \"html.parser\")\n",
    "    found_partial = soup.find(string=re.compile('Page 1 of '))\n",
    "    if found_partial:\n",
    "        max_page = int(found_partial.split(' of ')[1])\n",
    "        print(f\"Max page: {max_page}\")\n",
    "        return max_page\n",
    "    else:\n",
    "        print(\"Max page not found\")\n",
    "        return 0\n",
    "\n",
    "def get_programs_table() -> pd.DataFrame:\n",
    "    # The URL of the webpage you want to scrape\n",
    "    url = \"https://www.fisheries.noaa.gov/inport/help/components/programs?page=0\"\n",
    "    # Get the maximum page number from the webpage.\n",
    "    max_page = get_max_page_number_from_inport(url=url)\n",
    "\n",
    "    # Create an empty list to store DataFrames for each page\n",
    "    dfs = []\n",
    "\n",
    "    for curr_page in range(max_page):\n",
    "        url = f\"https://www.fisheries.noaa.gov/inport/help/components/programs?page={curr_page}\"\n",
    "        r = requests.get(url)\n",
    "\n",
    "        # Use pandas to read all tables on the page\n",
    "        # This returns a list of DataFrames\n",
    "        tables = pd.read_html(url)\n",
    "\n",
    "        # Access the first table in the list (index 0)\n",
    "        dfs.append(tables[0])\n",
    "\n",
    "    # Concatenate all DataFrames in the list into a single DataFrame\n",
    "    programs_table = pd.concat(dfs, ignore_index=True)\n",
    "    return programs_table\n",
    "\n",
    "get_programs_table()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "aalibrary",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
